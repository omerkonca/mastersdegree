https://miro.medium.com/v2/resize:fit:1400/1*7PQo9SP47PCTibXV2FyGsw.png
(143 kB)
https://miro.medium.com/v2/resize:fit:1400/1*7PQo9SP47PCTibXV2FyGsw.png

9:42
https://sefiks.com/2020/01/04/a-step-by-step-perceptron-example/#google_vignette
Sefik Ilkin SerengilSefik Ilkin Serengil
A Step by Step Perceptron Example - Sefik Ilkin Serengil
Understanding single layer perceptron will help you to understand deep learning as well. Because deep neural networks are combination of nested perceptrons
Written by
Sefik Serengil
Est. reading time
4 minutes
Jan 4th, 2020
https://sefiks.com/2020/01/04/a-step-by-step-perceptron-example/#google_vignette

9:42
https://github.com/serengil/tensorflow-101/blob/master/python/single-layer-perceptron.py
GitHubGitHub
tensorflow-101/python/single-layer-perceptron.py at master · serengil/tensorflow-101
TensorFlow 101: Introduction to Deep Learning. Contribute to serengil/tensorflow-101 development by creating an account on GitHub. (97 kB)
https://github.com/serengil/tensorflow-101/blob/master/python/single-layer-perceptron.py

9:42
https://media.licdn.com/dms/image/D4D12AQElGrpg2NiisQ/article-cover_image-shrink_600[…]47483647&v=beta&t=iBiIxGUrle6a1mlTadU-0vWvyVjCxW7DBa5qXqK_Qa4
(37 kB)
https://media.licdn.com/dms/image/D4D12AQElGrpg2NiisQ/article-cover_image-shrink_600_2000/0/1707688084849?e=2147483647&v=beta&t=iBiIxGUrle6a1mlTadU-0vWvyVjCxW7DBa5qXqK_Qa4

9:42
https://miro.medium.com/v2/resize:fit:1400/0*IYeBGx90QcOfvX0w.png
(66 kB)
https://miro.medium.com/v2/resize:fit:1400/0*IYeBGx90QcOfvX0w.png

9:42
https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=[…]se&problem=classification&initZero=false&hideText=false
playground.tensorflow.orgplayground.tensorflow.org
Tensorflow — Neural Network Playground
Tinker with a real neural network right here in your browser. (164 kB)
https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.003&regularizationRate=0&noise=0&networkShape=3,3&seed=0.20538&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false

9:43
https://poloclub.github.io/cnn-explainer/
poloclub.github.iopoloclub.github.io
CNN Explainer
An interactive visualization system designed to help non-experts learn about Convolutional Neural Networks (CNNs). (231 kB)
https://poloclub.github.io/cnn-explainer/

9:43
https://poloclub.github.io/transformer-explainer/
poloclub.github.iopoloclub.github.io
Transformer Explainer: LLM Transformer Model Visually Explained
An interactive visualization tool showing you how transformer models work in large language models (LLM) like GPT. (181 kB)
https://poloclub.github.io/transformer-explainer/

9:43
TRANSFORMERS - El ile tek tek hesaplama çalıştığımız notlar:   https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1 (edited) 
MediumMedium
Solving Transformer by Hand: A Step-by-Step Math Example
Performing numerous matrix multiplications to solve the encoder and decoder parts of the transformer
Reading time
13 min read
Dec 21st, 2023
https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1

9:44
https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/
MachineLearningMastery.comMachineLearningMastery.com
A Gentle Introduction to Positional Encoding in Transformer Models, Part 1 - MachineLearningMastery.com
Introduction to how position information is encoded in transformers and how to write your own positional encoder in Python.
Written by
Mehreen Saeed
Est. reading time
7 minutes
Sep 19th, 2022
https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/

9:44
https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder
magazine.sebastianraschka.commagazine.sebastianraschka.com
Understanding Encoder And Decoder LLMs
Several people asked me to dive a bit deeper into large language model (LLM) jargon and explain some of the more technical terms we nowadays take for granted. This includes references to "encoder-style" and "decoder-style" LLMs. What do these terms mean? (39 kB)
